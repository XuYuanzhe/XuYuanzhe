# 2021面经

#### 3/2 

* **19:00** 百观科技 电话面试

#### 3/3 

- **18:30** 启明合心 电话面试

#### 3/4 

-  __11:00__ 阿凡提教育 视频面试

  - <a href="#">面试房间</a>

  `leetcode 66 56 474`

- __12:30__ 旭闻科技 视频面试（修改面试时间至3/5）

- **15:00** 途游游戏 __现场面试__

  * <a href="#">朝阳区 暖山生活广场 B座3F</a>

```
python携程与进程的区别？
    进程有自己的内存空间，数据栈；协程是一种微线程，自带CPU上下文，若想使用协程则程序中必须有等待，协程执行任务更节省资源。
cpython的dict底层使用的数据结构？
    哈希表，key必须是可哈希对象。
cpython的gc有哪几种？
    引用计数；标记-清除；分代回收
OSI网络分层模型？
    物理层-数据链路层-网络层-传输层-会话层-表示层-应用层
TCP/UDP的区别？
列举五种设计模式？
    单例模式——保证一个类仅有一个实例,并提供一个访问它的全局控制点。比如在加载配置文件时, 可使用该模式。
    工厂模式——定义一个用以创建对象的接口, 让子类决定实例化哪个类。当遇到需要根据某个前提条件创建不同的类实现时, 会实用工厂模式
    装饰者模式——动态的给一个类添加额外的指责。
列举redis的五种数据类型，及应用场景，及底层数据结构？
    String可以用来存储字符串、整数、浮点数。
        全局ID：使用int类型的incrby的原子性；
        热点数据缓存；
        数据共享：如分布式Session缓存；
    Hash可以将相关的值聚集存储在一起，节省内存空间。
    ziplist：OBJ_ENCODING_ZIPLIST(压缩列表)
    hashtable：OBJ_ENCODING_HT(哈希表)
        存储对象类型的数据，如缓存数据表的数据
    Set	String 类型的无序集合
        点赞、签到、打卡、标签、抽奖
    List存储有序的字符串(从左到右)，元素可以重复。可以充当队列和栈的角色。
        消息队列。
    Zset
如何使用redis实现分布式锁？
redis的内存管理机制与gc？
    1.被动过期（惰性删除）：key被访问时，如果发现它已经过期就删除。
    2.主动过期（定期删除）：周期性地从过期字典中选择一部分失效的主键删除。
mongo的ObjectId包含哪些信息？
    是一个12字节的BSON类型字符串：UNIX时间戳；运行MongoDB的机器；生成此_id的进程；由一个随机数开始的计数器生成的值。
mongo索引有哪几种类型？
mongo索引用到什么数据结构？
mongo分片集群的架构？
```

* **17:30** 百观科技 __现场面试__

  * <a href="#">东城区 东直门南大街 来福士办公楼2206室</a>

```
时间复杂度为O(1)的列表去重操作？
```

#### 3/5

- **10:30** 阿凡提教育 **现场面试**

  - <a href="#">海淀区 清河永泰园甲一号 建金中心401-403室</a>

```python
# 在1亿数据中找到最大的1w个？
data_list = []
def foo():
    max_list = []
    for data in data_list:
      if data not in max_list:
        max_list.append(data)
        if len(max_list) > 10001:
          max_list.remove(min(max_list))
    return max_list
```

- __12:30__ 旭闻科技 **视频面试**

  - <a href="https://meeting.tencent.con/s/9mpm7thtmnkc">面试房间</a>

    `leetcode54`

- **16:00 **启明合心 **现场面试**

  - <a href="#">海淀区 知春路 量子芯座1607室</a>

```python
# 台阶问题/斐波那契
fib = lambda n: n if n <= 2 else fib(n - 1) + fib(n - 2)

def fib(n):
    a, b = 0, 1
    for _ in range(n):
        a, b = b, a + b
    return a
```

- **19:00** 百度 **视频面试**

  - <a href="https://infoflow.baidu.com/voip/api/meeting/middle/index.html?id=54c7cf2be36c4c3d303151d6a6f1a345#/pc">面试房间</a>

```
leetcode 24 15
列表和元组的区别是什么?
  元组和列表最大的区别就是，列表中的元素可以进行任意修改，就好比是用铅笔在纸上写的字，写错了还可以擦除重写；而元组中的元素无法修改，除非将元组整体替换掉，就好比是用圆珠笔写的字，写了就擦不掉了，除非换一张纸；可以理解为，tuple 元组是一个只读版本的 list 列表。
已经有了list类型为什么有tuple类型数据?
```


#### 3/6

- **11:30** BuzzBreak旭闻科技 **现场面试**

  - <a href="#">海淀区 马甸东路 金奥国际商业区206号</a>

```
用Redis来实现限制一个api或页面访问的频率，例如单ip或单用户一分钟之内只能访问多少次？

在redis中保存一个count值（int），key为user:$ip，value为该ip访问的次数，第一次设置key的时候，设置expires。
count加1之前，判断是否key是否存在，不存在的话，有两种情况：1、该ip未访问过；2、该ip访问过，但是key已经过期了。那么此时需要再次设置一次expires。如果用户访问的时候，判断count的值是否大于上限，如果低于上限，就处理请求，否则就拒绝处理请求。

# 考虑这种情况，假设只允许用户60秒内访问100次，如果有一个用户在第1秒访问了1次，在第59秒的时候，访问了99次，然后在第61秒的时候，访问了100次。如果按照策略1的情况处理，第1~60秒之间接受了100次，在第61秒接收100次请求，所以62~120这段时间内，不再处理该ip的请求。貌似没问题，但是，细细思考一下，第59秒到61秒之间接受了99+100=199请求，时间间隔只有3秒。那么这样的话，最初的设计就存在问题了。
解决方案：可以使用redis的list（双向队列）数据结构，key就是user:$ip，也就是每一个ip设置一个双向队列，每次请求到达的时候，进行如下判断：
1、如果list中的元素个数少于100个，那么就将请求到达时的时间戳Lpush到list中。
2、如果list中的元素多余100个，那么，就取出Lindex(-1)即最右边，也就是100个请求中最早的那一个请求的时间戳，如果最早的时间戳和当前时间戳相差超过60秒，那么表示第一个请求已经过期了，就将第一个请求出队Rpop。然后将当前时间戳入队Lpush
```

#### 3/11

- **20:00** 学堂在线 **笔试文件**
- **20:00** 百度视频 **视频面试**
  - <a href="https://meeting.tencent.com/s/fEo6TQMpTQYI">面试房间</a>

#### 3/12

- **11:00** Moka **现场面试**

  - <a href="#">北京市 海淀区 知春路68号领航科技大厦4层</a>

```python
# 手写装饰器 面向切片编程 
import functools

def decorator(fn):
  context = 1
  
  @functools.wraps(fn)
  def wrapper(*args, **kwargs):
    print("context", context)
    return fn(*args, **kwargs)
  return wrapper


@decorator
def func():
  print("I am target")

func()


#带参数的装饰器
def decorator(n):
  def func(f):
    @functiontools.wraps(f)
    def wrapper(*args, **kwargs):
      print(n)
      return f(*args, **kwargs)
    return wrapper
  return func

@decorator(3)
def test(*args, **kwargs):
  print(1)
```

- **15:00** 天眼查 **视频面试**

  - <a href="https://interview.nowcoder.com/interview/19553573/interviewee?code=2bIX4HKc">面试房间</a>

    `寻找第K大`

#### 3/16

- **20:00** 百度 **视频面试**

  - <a href="https://infoflow.baidu.com/voip/api/meeting/middle/index.html?id=201f6a8f9eed52990f6b46ac3e398180#/pc">面试房间</a>

```python
# 一个自然数可以分解为若干个自然数相乘，对于指定自然数n,请求出每种分解自然数之和最小的一个（不考虑1，若是素数，则是它本身）
def foo(n):
    rv = []
    for i in range(2, n+1):
        if n % i == 0:
            ii = n // i
            rv.append(i + ii)
    return min(rv)

if __name__ == "__main__":
    foo(24)
```

#### 3/17

- **10:00** GamesVessel **现场面试**

  - <a href="#">海淀区 王庄路 清华同方科技广场D座东楼12层</a>

#### 3/20 

- **11:00** GamesVessel **现场面试**

#### 3/23

- **15:00** 猿辅导 **现场面试**（取消）
  - <a  href="#">朝阳区 阜荣街10号首开广场B座</a>

#### 3/28

* **14:00** 字节跳动 视频面试（取消）
  * <a href="https://people.toutiaocloud.com/hire/bridge/video/interviewee/893c9fe4-59e2-4592-b32d-1186a550a2f4">面试房间</a>

#### 9/14

* **15:00** 智线云科技 现场面试
  
![](https://raw.githubusercontent.com/XuYuanzhe/Figurebed/master/img/20210922185358.png)

⬆图一

![](https://raw.githubusercontent.com/XuYuanzhe/Figurebed/master/img/20210922185437.png)

⬆图二
```
一面
说说你解决过的最难的一个网页爬虫问题
了解MySQL的两种引擎吗？
redis有几种数据类型知道吗？
列举一下python常用的数据类型？
这其中哪些是可变的数据类型？
dict的底层逻辑是什？元组可以做dict的key吗？为什么？
做过py2向py3迁移，能列举几个他们的区别吗？


二面
scrapy框架中最重要的文件是哪一个？组合集成了middlewares、pipelines这些模块的那个文件叫什么？
    -scrapy.cfg是针对Scrapy框架的配置；settings.py是针对于项目本身的设置，比如用什么中间件、并发数量、UA、Pipelines等等
scrapy创建项目的时候都包含哪些文件说得上来吗？
    scrapy.cfg            # deploy configuration file
    tutorial/             # project's Python module, you'll import your code from here
        items.py          # project items definition file
        middlewares.py    # project middlewares file
        pipelines.py      # project pipelines file
        settings.py       # project settings file
        spiders/          # a directory where you'll later put your spiders
scrapy的工作模式是什么样的？
    -Scrapy框架主要由六大组件组成，它们分别是调度器(Scheduler)、下载器(Downloader)、爬虫（Spider）、中间件（Middleware）、实体管道(Item Pipeline)和Scrapy引擎(Scrapy Engine)
    1、Scrapy Engine(引擎): 引擎负责控制数据流在系统的所有组件中流动，并在相应动作发生时触发事件。
    2、Scheduler(调度器): 调度器从引擎接受request并将他们入队，以便之后引擎请求他们时提供给引擎。
    3、Downloader（下载器）： 下载器负责获取页面数据并提供给引擎，而后提供给spider。
    4、Spider（爬虫）： Spider是Scrapy用户编写用于分析response并提取item(即获取到的item)或额外跟进的URL的类。 每个spider负责处理一个特定(或一些)网站。
    5、Item Pipeline(管道)： Item Pipeline负责处理被spider提取出来的item。典型的处理有清理、 验证及持久化(例如存储到数据库中)。
    6、Downloader Middlewares（下载中间件）： 下载器中间件是在引擎及下载器之间的特定钩子(specific hook)，处理Downloader传递给引擎的response。 其提供了一个简便的机制，通过插入自定义代码来扩展Scrapy功能。
    7、Spider Middlewares（Spider中间件）： Spider中间件是在引擎及Spider之间的特定钩子(specific hook)，处理spider的输入(response)和输出(items及requests)。 其提供了一个简便的机制，通过插入自定义代码来扩展Scrapy功能。
聊一聊你在工作中使用git的一些命令和方法
聊一聊Linux你用过的一些指令吧
怎么查询日志最近的一条输出？
    -tail -f -n 10
我写一个例子 <s>://<host>:<port>/<path> 把他理解为一个url这样完整吗？
    -不完整，但说不上来
访问http://www.baidu.com实际上是访问了哪里？
连接数据库需要哪些信息？
    -host、port、user、pwd、db这些吧
    -那这些是怎么组合起来访问的呢？
    -<s>://<host>:<port>/？user=xxx&pwd=xxx
    -应该是 <s>://<username>:<password>@<host>:<port>/<path>
说说你这里的gRPC是什么吧
    -gRPC是google开源的一个高性能、跨语言的RPC框架
那怎么理解RPC？他是基于什么实现的呢？比如http服务是基于http协议的
    -Remote Procedure Call Protocol（远程过程调用协议）本质的区别就是RPC主要是基于TCP/IP协议的
你这里不可以写shell命令，他是一种应用程序那你说说$1在shell中是什么含义
    -第一个传递的参数
    -那$0呢
    -不知道(Shell本身的文件名)
    -` `用过吗？可以讲讲吗？
    -没用过(被单引号括起来的字符都是普通字符，就算特殊字符也不再有特殊含义；而被双引号括起来的字符中，"$"、"\"和反引号是拥有特殊含义的，"$"代表引用变量的值，而反引号代表引用命令)
    你这里写Flask + Rdis + JavaScript那flask他是一个server吗？
    -用flask写了一个简单的server
    -怎么启动服务的呢？
    -python main.py
    -这里不会有一些问题吗？如果现在服务挂掉了怎么办？
    -不知道
    -uwsgi听说过吗？
    -听说过，具体记不清了
    -有用过Django的框架吗？
    -写过简单的blog项目
    -那你写blog里面的登陆发布这些模块叫什么知道吗？
    -不知道
    -叫应用，是app，所以你启的这个main.py不能称之为是一个service，应该用uwsgi+nginx来做，了解nginx吗？
    -好像是做负载均衡的
    -嗯 呐说说你知道哪些负载均衡的模式
    -记不清了（基于DNS负载均衡[解析ip分配给服务器]，基于硬件负载均衡，基于软件负载均衡[根据OSI分为四层和七层负载均衡，本质上是把数据包偷天换日]）
    -正向代理与反向代理
    -两者的区别在于代理的对象不一样：正向代理代理的对象是客户端(科学上网工具)，反向代理代理的对象是服务端(拨打10086,访问baidu.com)
    两层结构（图一）
    在这种结构里,uWSGI作为服务器，它用到了HTTP协议以及wsgi协议，flask应用作为application，实现了wsgi协议。当有客户端发来请求，uWSGI接受请求，调用flask app得到相应，之后相应给客户端。通常来说，Flask等web框架会自己附带一个wsgi服务器(这就是flask应用可以直接启动的原因)，但是这只是在开发阶段用到的，在生产环境是不够用的。
    
    三层结构（图二）
    这种结构里，uWSGI作为中间件，它用到了uwsgi协议(与nginx通信)，wsgi协议(调用Flask app)。当有客户端发来请求，nginx先做处理(静态资源是nginx的强项)，无法处理的请求(uWSGI),最后的相应也是nginx回复给客户端的。
    
你也用过tornado框架，那你觉得它和flask、django这两个是一回事吗？
    -tornado是一个服务器程序，如何理解，我觉得比如tornado提供了控制webserver的方式，控制层面包括了各种webserver的细节。当然tornado中是可以定义对于web请求的返回
你这里说用过mitmporxy用它是帮助做什么事的呢？


三面
你的个人职业规划是什么？技术专精又或是架构师方向？
说一下你解决过的最难的问题？
有没有想过修改Selenium的一些参数让对方网站无法识别？
你说你注重专业基础学习，那我想问一下二叉查找树的时间复杂度是多少？
    -nlogn      应该是平衡状态下log2(N) 最慢是n在一条链上
    -这里的n是什么呢？
    -n个节点
二叉查找树和二分法哪个速度更快？
    -感觉一样快(  都是log2(n)  )
对操作系统有理解吗？
什么是僵尸进程什么是孤儿进程？
    -就是只要子进程退出，父进程还在运行，但父进程没有读取子进程状态，子进程进入僵尸状态（Z状态），会造成内存泄漏、内存资源浪费；父进程先于子进程退出，子进程会被1号进程领养，1号进程称init进程。1号进程会在子进程退出的时候，回收子进程的退出信息，防止子进程变成僵尸进程，没什么危害
```
  
  

#### 9/23

* **10:30** 懂球帝 现场面试
![](https://raw.githubusercontent.com/XuYuanzhe/Figurebed/master/img/20210922172935.png)

⬆图三

```
手写一个快排算法
def quick_sort(arr):
    if arr==[]:
        return[]
    else:
        first=arr[0]
        left=quick_sort([l for l in arr[1:]if l<first])
        right=quick_sort([r for r in arr[1:]if r>=first])
        return left+[first]+right 
手写一个字符串反转
a = '123456789'
b = a[::-1]
b = ''.join(reversed(a))
画一个scrapy的架构图
    -图三
redis的几种数据结构了解吗？
    String可以用来存储字符串、整数、浮点数。
        全局ID：使用int类型的incrby的原子性；
        热点数据缓存；
        数据共享：如分布式Session缓存；
    Hash可以将相关的值聚集存储在一起，节省内存空间。
    ziplist：OBJ_ENCODING_ZIPLIST(压缩列表)
    hashtable：OBJ_ENCODING_HT(哈希表)
        存储对象类型的数据，如缓存数据表的数据
    Set	String 类型的无序集合
        点赞、签到、打卡、标签、抽奖
    List存储有序的字符串(从左到右)，元素可以重复。可以充当队列和栈的角色。
        消息队列。
    Zset
怎么判断二叉树平衡？
```


* **14:00** Momenta 电话面试
```
说说进程线程和协程？
都说python慢，慢在哪里？
    -全局解释器锁(Global Interpreter Lock)（GIL）, 是因为 Python 是解释型语言而不是编译型语言, 是因为 Python 是一种动态类型的语言”
python2和python3的区别你觉得哪个点你印象比较深？
```


* **15:00** 知乎 现场面试
```
一个数组把0放在右边其他元素顺序排列不变
说说三次握手四次挥手？
如果 C 发送的 ack S 没有接收会出现什么情况？
二叉树的三种遍历?
    -前、中、后（基于根节点）
说说进程线程和协程？
    -最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。
    -第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。
    -因为协程是一个线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能
那协程是用户态还是内核态？
    -协程就是一种用户态内的上下文切换技术，协程是一种用户态的轻量级线程。
画一个scrapy的架构图
    -图三
redis的几种数据结构了解吗？
git出现冲突pull不下code怎么解决？
什么是死锁？怎么避免？
    -当线程互相持有对方所需要的资源时，会互相等待对方释放资源，如果线程都不主动释放所占有的资源，将产生死锁。
    -尝试获取锁的时候加一个超时时间，这也就意味着在尝试获取锁的过程中若超过了这个时限该线程则放弃对该锁请求。
    -银行家算法是避免死锁的一种重要方法
```


* **18:00** 领创集团 现场面试
```
dict的底层是什么实现的？时间复杂度是多少？为什么？
    - hash map, O(1), 
MySQL写一条select最重要的是什么？
    -命中索引
手写一个二叉树中序遍历的递归
def preorder(tree):
  if tree is None:
    return
  print(tree.value)   # 前序遍历 value  left  right
  preorder(tree.left)
  print(tree.value)   # 中序遍历 left  value  right
  preorder(tree.right)
  print(tree.value)   # 后序遍历  left  right value
都说python的多线程是假的但是为什么还要用多线程？好在哪里？
    -多线程有两个好处：CPU并行，IO并行。Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。(多核多线程比单核多线程更差，原因是单核下的多线程，每次释放GIL，唤醒的那个线程都能获取到GIL锁，所以能够无缝执行，但多核下，CPU0释放GIL后，其他CPU上的线程都会进行竞争，但GIL可能会马上又被CPU0拿到，导致其他几个CPU上被唤醒后的线程会醒着等待到切换时间后又进入待调度状态，这样会造成线程颠簸(thrashing)，导致效率更低)
你怎么理解这个分布式爬虫的分布式
    -url 被分给不同的爬虫，但是不同爬虫的效率又是不一样的，所以说共享队列，共享数据，让效率高的爬虫多去做任务，而不是等着效率低的爬虫
说说yeild函数
    -在一个函数中，程序执行到yield语句的时候，程序暂停，返回yield后面表达式的值，在下一次调用的时候，从yield语句暂停的地方继续执行，如此循环，直到函数执行完。
```


#### 9/24

* **15:00** 小黑盒 电话面试
  - <a href="https://leetcode-cn.com/problems/3sum/">三数之和</a>
  - <a href="https://leetcode-cn.com/problems/find-peak-element/">寻找峰值</a>
```
二叉树两节点的最大路径长度
一个数组 里面包含012 要求左边放0右边放1 中间是2 时间复杂度0n；
手写一个链表的插入删除方法 
```


#### 9/26

* **10:30** 滴滴
  

* **14:00** 知乎 二面


* **17:00** 小黑盒 二面

-----

**python的内存管理机制，如何避免循环引用的问题**

引用计数；分代回收；标记-清除

https://zhuanlan.zhihu.com/p/124290355

当一个对象有新的引用时，对象的引用计数+1；当一个对象的引用被销毁时，对象的引用计数-1；

循环引用导致引用计数不能清零会造成内存泄漏；函数的参数适用了可变变量 `list` `dict`  而默认不是这种可变变量

如果循环引用中，两个对象都定义了*__del__*方法，gc模块不会销毁这两个不可达对象，因为gc模块不知道应该先调用哪个对象的*__del__*方法（例如，两个对象a和b，如果先销毁a，则在销毁b时，会调用b的*__del__*方法，该方法中很可能使用了a，这时会造成异常），所以为了安全起见，gc模块会把对象放到*gc.garbage*中，并把它们称为uncollectable。很明显，这种情况会造成内存泄漏，要解决的话，只能显式调用其中某个对象的*__del__*方法来打破僵局。


**在python中随机化列表中的元素**

```
numpy.random.randint(k, size=n)
numpy.random.shuffle(seq)
random.sample(seq, k)
random.choice(seq)
```



**python iterator generator**

​						迭代器	生成器

可迭代对象	 序列 (字符串，列表，元组)

​						字典

可迭代的对象的意思是就是说这个实体是可迭代的，例如字符、列表、元组、字典、迭代器等等，可以用for ... in进行循环，可以使用for循环迭代的标志是内部实现了`__iter__`方法。

可迭代对象仅含有`__iter__`的内部方法，你可以通过封装next()方法（python3中为`__next__()`）来将其做成一个迭代器，以生成器（generator，特殊的函数类型的迭代器）为例，你可以通过yield关键字来做一个迭代器，只不过名字被叫做generator，yield可以看做就是为对象添加了`__iter__`方法和指示下一次迭代的`next()/__next__()`方法。

使用isinstance(实体名,Iterable)可判断是否为可迭代对象

在py2中 range 和 xrange 前者返回list后者返回的是一个生成器，不会一下子开辟出所有的内存空间，生成一个开一个。



**with 语法的实现方式**

帮助实现了一个`__enter__` 和 `__exit__` 的方法。读取和退出的时候自动调用，在操作文件或网络的异步操作的时候很有用。



**python 类里面的mixin的用法**

相当于一种多重继承，子类拥有所有父类的变量、成员函数。



**如何创建一个python的元类**

实例对象是由类来创建，类是由元类来创建的。

python的类都是由 `type` 类继承的，可以想象为元类是一个类的父类。

在Django中多用元类创建语法糖。



**python的线程进程和携程协程**

进程：是CPU对程序的一次**执行过程**、一次**执行任务**。各个进程有自己的内存空间、数据栈等。

线程：是进程中执行运算的最小单位，是进程中的一个**实体**。

协程：比线程更小的执行单元，又称微线程，在单线程上执行多个任务，自带CPU上下文。想要使用协程，那么我们的任务必须有等待。当我们要完成的任务有耗时任务，属于IO密集型任务时，我们使用协程来执行任务会节省很多的资源。

python使用`threading`实现多线程，使用`gevent + asyncio`实现携程。在Python的进程里只有一个GIL。一个线程需要执行任务，必须获取GIL。

​	* 好处：直接杜绝了多个线程访问内存空间的安全问题。

​	* 坏处：Python的多线程不是真正多线程，不能充分利用多核CPU的资源。



**py2和py3的区别，把项目从py2迁移到py3会遇到哪些困难？**

print不再是语句，而是函数；Python2 默认编码是 ASCII，Python3 默认编码是 Unicode(utf-8)；在 Python2 中很多返回列表对象的内置函数和方法在 Python3 都改成了返回类似于迭代器的对象，因为迭代器的惰性加载特性使得操作大数据更有效率；True 和 False 在 Python2 中是两个全局变量，在数值上分别对应 1 和 0。Python3 修正了这个缺陷，True 和 False 变为两个关键字。





**python性能调优**

首先看瓶颈在哪里，如果在CPU计算比较重可以用c实现一下；如果是跟code关系不大主要是网络数据库这一块，就要看sql语法和携程调用有没有充分使用；`line_profiler` 在code里写上可以帮助分析这一块的性能； `cProfiler` 帮助分析整体性能；火焰图 



**编写高质量代码**

Type Hints 写的话不仅IDE可以提示你类型与参数；在一些库里可以的到比较友好的提示和错误处理



**同步异步阻塞非阻塞**

- 同步和异步关注的是**消息通信机制**。所谓同步，就是在发出一个*调用*时，在没有得到结果之前，该调用就不返回；而异步则是相反，调用在发出之后，这个调用就直接返回了，所以没有返回结果**。

  你打电话问书店老板有没有《分布式系统》这本书，如果是同步通信机制，书店老板会说，你稍等，”我查一下"，然后开始查啊查，等查好了（可能是5秒，也可能是一天）告诉你结果（返回结果）。
  而异步通信机制，书店老板直接告诉你我查一下啊，查好了打电话给你，然后直接挂电话了（不返回结果）。然后查好了，他会主动打电话给你。在这里老板通过“回电”这种方式来回调。

- 阻塞和非阻塞关注的是**程序在等待调用结果（消息，返回值）时的状态**。阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回；非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。

  你打电话问书店老板有没有《分布式系统》这本书，你如果是阻塞式调用，你会一直把自己“挂起”，直到得到这本书有没有的结果，如果是非阻塞式调用，你不管老板有没有告诉你，你自己先一边去玩了， 当然你也要偶尔过几分钟check一下老板有没有返回结果。
  在这里阻塞与非阻塞与是否同步异步无关。跟老板通过什么方式回答你结果无关

  

**http 1.0 / 1.1 / 2.0**

首先http协议是一种构建在TCP协议之上的应用层协议,主要是用途客户端和服务端的沟通.

- HTTP1.1默认使用长连接，可有效减少TCP的三次握手开销。
- HTTP 1.1支持只发送header信息(不带任何body信息)，如果服务器认为客户端有权限请求服务器，则返回100，否则返回401。客户端如果接受到100，才开始把请求body发送到服务器。这样当服务器返回401的时候，客户端就可以不用发送请求body了，节约了带宽。
- HTTP2.0对header压缩；使用多路复用技术，多路复用允许同时通过单一的 HTTP/2 连接发起多重的请求-响应消息。



**TCP/IP**

- 应用层

- 表示层

- 会话层

- 传输层

  |            | TCP                                              | UDP                                        |
  | ---------- | ------------------------------------------------ | ------------------------------------------ |
  | 可靠性     | 可靠                                             | 不可靠                                     |
  | 连接性     | 面向连接                                         | 无连接                                     |
  | 效率       | 传输效率低                                       | 传输效率高                                 |
  | 双工性     | 全双工                                           | 一对一、一对多、多对一、多对多             |
  | 传输速度   | 慢                                               | 快                                         |
  | 应用场景   | 对效率要求低，对准确性要求高或者要求有链接的场景 | 对效率要求高，对准确性要求低的场景         |
  | 应用层协议 | SMTP电子邮件/HTTP万维网/FTP文件传输              | DNS域名转换/TFTP文件传输/NFS远程文件服务器 |

  

- 网络层				

  - 路由器	拥有独立MAC帮助转发，本身没有传输包的功能实际传输是委托给数据链路层的

  - IP协议是不可靠协议，数据处理被认为是上层协议要做的事

  - 32位IP地址分为网络位和地址位，这样可以减少路由表记录的数目

    - A类IP地址：0.0.0.0 ～1 27.0.0.0
    - B类IP地址：128.0.0.1 ～ 191.255.0.0
    - C类IP地址：192.168.0.0 ～ 239.255.255.0

    

- 数据链路层		
  - 交换机	通过维护一张MAC地址表，只发送给目标MAC地址指向的那一台电脑（以太网）

- 物理层				
  - 集线器	无脑将信号转发给所有MAC地址

**swap 虚拟内存**

虚拟内存则是虚拟出来的、使用磁盘代替内存。memory就是机器的物理内存，读写速度低于cpu一个量级，但是高于磁盘不止一个量级。所以，程序和数据如果在内存的话，会有非常快的读写速度。内存的断电丢失数据是一个不能把所有数据和程序都保存在内存中对原因。当内存没有可用的，就必须要把内存中不经常运行的程序给踢出去。但是踢到哪里去，这时候swap就出现了。**swap全称为swap place，即交换区**，当内存不够的时候，被踢出的进程被暂时存储到交换区。当需要这条被踢出的进程的时候，就从交换区重新加载到内存，否则它不会主动交换到真实内存中。



**常用的Linux指令**

ps grep ls ll touch cp cat vim scp top cd rm mkdir mv which su pwd kill zip



**MySQL**

* InnoDB和MyISAM
  * InnoDB 支持事务，MyISAM 不支持事务
  * InnoDB 支持外键，而 MyISAM 不支持
  * InnoDB 是聚集索引，MyISAM 是非聚集索引



**Redis**

默认有16个数据库

常用数据结构 `string` `set` `hset` 虚拟化数据大多都可以存储为`string`

淘汰机制有哪些？

​	每隔一段时间扫描如果设置了TTL到点就删除；或下次访问key时候删掉数据；···

为什么快？除了他是内存型数据库外，还有什么原因？



**冒泡排序\快速排序\你了解的排序算法**





**实现一个秒杀功能千万级 会考虑哪些点？**

第一点还是从业务上避免这么大规模的访问，抢服务器资源，做访问限制（小米手机之前的发售就是在前端弹一个窗口，根本没有发数据给服务器）。或者支持服务器弹性伸缩，否则是一种资源的浪费；

第二点在于不要落库，落库操作要有序进行，业务线进来放入队列或者缓存再有序落库；

多台机器负载均衡；

像微信红包这样在创建红包的时候已经分配好了每个红包多少钱，抢的过程只是取的过程。

python比较慢的话换个语言

